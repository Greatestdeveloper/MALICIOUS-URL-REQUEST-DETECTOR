{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b647c3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\1MYFILES\\ML_NGFW\\FIREWALLS\\-Phishing url detection\n"
     ]
    }
   ],
   "source": [
    "cd D:\\1MYFILES\\ML_NGFW\\FIREWALLS\\-Phishing url detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ba99476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.12\n"
     ]
    }
   ],
   "source": [
    "!python --version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf6be720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\lanka\\anaconda3\\lib\\site-packages (0.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cec6b10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\lanka\\anaconda3\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\lanka\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\lanka\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\lanka\\anaconda3\\lib\\site-packages (from selenium) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\lanka\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\lanka\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\lanka\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\lanka\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.0.4)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\lanka\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: idna in c:\\users\\lanka\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lanka\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\lanka\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\lanka\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lanka\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\lanka\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\lanka\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\lanka\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "# import seaborn as sb # helps in statistical data visualization in different forms\n",
    "import matplotlib.pyplot as plt # plots the data\n",
    "%matplotlib inline \n",
    "\n",
    "import time \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB # a simple learning algo which used bayes rule assuming the objects having some characteristics \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer # Tokenizes the url to get the required words\n",
    "from nltk.stem.snowball import SnowballStemmer # stemms different works into meaningless words \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer # Vectorizes the tokens into a matrix \n",
    "from sklearn.pipeline import make_pipeline \n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "!pip install selenium \n",
    "from selenium import webdriver\n",
    "import networkx as nx # plots the internal link redirections within a website\n",
    "\n",
    "import pickle # we'll store data in form of non-primitives and that has to be converted to character stream when we train it and \"pickle\" helps us to do that \n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80424da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nobell.it/70ffb52d079109dca5664cce6f317373782/...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.dghjdgf.com/paypal.co.uk/cycgi-bin/webscrc...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>serviciosbys.com/paypal.cgi.bin.get-into.herf....</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mail.printakid.com/www.online.americanexpress....</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thewhiskeydregs.com/wp-content/themes/widescre...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549341</th>\n",
       "      <td>23.227.196.215/</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549342</th>\n",
       "      <td>apple-checker.org/</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549343</th>\n",
       "      <td>apple-iclods.org/</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549344</th>\n",
       "      <td>apple-uptoday.org/</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549345</th>\n",
       "      <td>apple-search.info</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>549346 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      URL Label\n",
       "0       nobell.it/70ffb52d079109dca5664cce6f317373782/...   bad\n",
       "1       www.dghjdgf.com/paypal.co.uk/cycgi-bin/webscrc...   bad\n",
       "2       serviciosbys.com/paypal.cgi.bin.get-into.herf....   bad\n",
       "3       mail.printakid.com/www.online.americanexpress....   bad\n",
       "4       thewhiskeydregs.com/wp-content/themes/widescre...   bad\n",
       "...                                                   ...   ...\n",
       "549341                                    23.227.196.215/   bad\n",
       "549342                                 apple-checker.org/   bad\n",
       "549343                                  apple-iclods.org/   bad\n",
       "549344                                 apple-uptoday.org/   bad\n",
       "549345                                  apple-search.info   bad\n",
       "\n",
       "[549346 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phish_data = {}\n",
    "phish_data = pd.read_csv('phishing_site_urls.csv')\n",
    "phish_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bba844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phish_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "588c7102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "URL      0\n",
       "Label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phish_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b6005f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>392924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>156422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label\n",
       "good  392924\n",
       "bad   156422"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = pd.DataFrame(phish_data.Label.value_counts())\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28fbf55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda activate py3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8b8b266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\lanka\\anaconda3\\lib\\site-packages (0.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "873c49de",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'remove_na' from 'pandas.core.series' (C:\\Users\\lanka\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msb\u001b[39;00m \n\u001b[0;32m      2\u001b[0m sb\u001b[38;5;241m.\u001b[39mset_style(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdarkgrid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m sb\u001b[38;5;241m.\u001b[39mbarplot(label_counts\u001b[38;5;241m.\u001b[39mindex,label_counts\u001b[38;5;241m.\u001b[39mLabel)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\__init__.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpalettes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinearmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategorical\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtimeseries\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\categorical.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseries\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m remove_na\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PatchCollection\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'remove_na' from 'pandas.core.series' (C:\\Users\\lanka\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py)"
     ]
    }
   ],
   "source": [
    "import seaborn as sb \n",
    "sb.set_style('darkgrid')\n",
    "sb.barplot(label_counts.index,label_counts.Label)\n",
    "# sb.barplot( index , labels ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d538e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'[A-Za-z]+') # tokenizes the given url based on the string argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9367bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing all the rows\n",
    "# by passing all the URLs into the anonymous function i.e. mapping all the URLs into anonymous function.\n",
    "# we use anonymous functions here for simplicity of code and no requirement of creating a function and storing it.\n",
    "phish_data['text_tokenized'] = phish_data.URL.map(lambda t: tokenizer.tokenize(t)) # doing with all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "512af4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Label</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13048</th>\n",
       "      <td>'taesx.com/img/?us.battle.net/login/en/?ref=ht...</td>\n",
       "      <td>bad</td>\n",
       "      <td>[taesx, com, img, us, battle, net, login, en, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66986</th>\n",
       "      <td>tools.ietf.org/html/rfc1082</td>\n",
       "      <td>good</td>\n",
       "      <td>[tools, ietf, org, html, rfc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347222</th>\n",
       "      <td>google.com/finance?cid=16393552</td>\n",
       "      <td>good</td>\n",
       "      <td>[google, com, finance, cid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293715</th>\n",
       "      <td>bodytronics.com/p/robic_stopwatches/RO501</td>\n",
       "      <td>good</td>\n",
       "      <td>[bodytronics, com, p, robic, stopwatches, RO]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387830</th>\n",
       "      <td>metacritic.com/redirectcritic?m=milk2008</td>\n",
       "      <td>good</td>\n",
       "      <td>[metacritic, com, redirectcritic, m, milk]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      URL Label  \\\n",
       "13048   'taesx.com/img/?us.battle.net/login/en/?ref=ht...   bad   \n",
       "66986                         tools.ietf.org/html/rfc1082  good   \n",
       "347222                    google.com/finance?cid=16393552  good   \n",
       "293715          bodytronics.com/p/robic_stopwatches/RO501  good   \n",
       "387830           metacritic.com/redirectcritic?m=milk2008  good   \n",
       "\n",
       "                                           text_tokenized  \n",
       "13048   [taesx, com, img, us, battle, net, login, en, ...  \n",
       "66986                       [tools, ietf, org, html, rfc]  \n",
       "347222                        [google, com, finance, cid]  \n",
       "293715      [bodytronics, com, p, robic, stopwatches, RO]  \n",
       "387830         [metacritic, com, redirectcritic, m, milk]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phish_data.sample(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2de4ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bac86997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming all the repetetive words into meaning less words\n",
    "phish_data['text_stemmed'] = phish_data['text_tokenized'].map(lambda l: [stemmer.stem(word) for word in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87c6aacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Label</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>351575</th>\n",
       "      <td>hiphopdx.com/index/news/id.12390/title.trackli...</td>\n",
       "      <td>good</td>\n",
       "      <td>[hiphopdx, com, index, news, id, title, trackl...</td>\n",
       "      <td>[hiphopdx, com, index, news, id, titl, trackli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23194</th>\n",
       "      <td>freesteams.hut2.ru/</td>\n",
       "      <td>bad</td>\n",
       "      <td>[freesteams, hut, ru]</td>\n",
       "      <td>[freesteam, hut, ru]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438753</th>\n",
       "      <td>startribune.com/local/122631354.html</td>\n",
       "      <td>good</td>\n",
       "      <td>[startribune, com, local, html]</td>\n",
       "      <td>[startribun, com, local, html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339225</th>\n",
       "      <td>flickr.com/photos/jonathan_cohen/4565948098/</td>\n",
       "      <td>good</td>\n",
       "      <td>[flickr, com, photos, jonathan, cohen]</td>\n",
       "      <td>[flickr, com, photo, jonathan, cohen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194987</th>\n",
       "      <td>grenadamedia.com/</td>\n",
       "      <td>good</td>\n",
       "      <td>[grenadamedia, com]</td>\n",
       "      <td>[grenadamedia, com]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      URL Label  \\\n",
       "351575  hiphopdx.com/index/news/id.12390/title.trackli...  good   \n",
       "23194                                 freesteams.hut2.ru/   bad   \n",
       "438753               startribune.com/local/122631354.html  good   \n",
       "339225       flickr.com/photos/jonathan_cohen/4565948098/  good   \n",
       "194987                                  grenadamedia.com/  good   \n",
       "\n",
       "                                           text_tokenized  \\\n",
       "351575  [hiphopdx, com, index, news, id, title, trackl...   \n",
       "23194                               [freesteams, hut, ru]   \n",
       "438753                    [startribune, com, local, html]   \n",
       "339225             [flickr, com, photos, jonathan, cohen]   \n",
       "194987                                [grenadamedia, com]   \n",
       "\n",
       "                                             text_stemmed  \n",
       "351575  [hiphopdx, com, index, news, id, titl, trackli...  \n",
       "23194                                [freesteam, hut, ru]  \n",
       "438753                     [startribun, com, local, html]  \n",
       "339225              [flickr, com, photo, jonathan, cohen]  \n",
       "194987                                [grenadamedia, com]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phish_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c31186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining all the list elements without any commas \n",
    "phish_data['text_sent'] = phish_data['text_stemmed'].map(lambda l: ' '.join(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e48d6943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Label</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>164209</th>\n",
       "      <td>delhi.quikr.com/kpmg-india-internship-program-...</td>\n",
       "      <td>good</td>\n",
       "      <td>[delhi, quikr, com, kpmg, india, internship, p...</td>\n",
       "      <td>[delhi, quikr, com, kpmg, india, internship, p...</td>\n",
       "      <td>delhi quikr com kpmg india internship program ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312733</th>\n",
       "      <td>davidson.k12.nc.us/education/school/school.php...</td>\n",
       "      <td>good</td>\n",
       "      <td>[davidson, k, nc, us, education, school, schoo...</td>\n",
       "      <td>[davidson, k, nc, us, educ, school, school, ph...</td>\n",
       "      <td>davidson k nc us educ school school php sectionid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510936</th>\n",
       "      <td>unmannedsafetyinstitute.org/t76f3g</td>\n",
       "      <td>bad</td>\n",
       "      <td>[unmannedsafetyinstitute, org, t, f, g]</td>\n",
       "      <td>[unmannedsafetyinstitut, org, t, f, g]</td>\n",
       "      <td>unmannedsafetyinstitut org t f g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379285</th>\n",
       "      <td>lonestarball.com/2011/7/7/2263647/series-previ...</td>\n",
       "      <td>good</td>\n",
       "      <td>[lonestarball, com, series, preview, oakland, ...</td>\n",
       "      <td>[lonestarbal, com, seri, preview, oakland, ath...</td>\n",
       "      <td>lonestarbal com seri preview oakland athlet te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212195</th>\n",
       "      <td>mediagallery.usatoday.com/2010-11-NHL-season/G...</td>\n",
       "      <td>good</td>\n",
       "      <td>[mediagallery, usatoday, com, NHL, season, G]</td>\n",
       "      <td>[mediagalleri, usatoday, com, nhl, season, g]</td>\n",
       "      <td>mediagalleri usatoday com nhl season g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300590</th>\n",
       "      <td>cbssports.com/collegefootball/players/playerpa...</td>\n",
       "      <td>good</td>\n",
       "      <td>[cbssports, com, collegefootball, players, pla...</td>\n",
       "      <td>[cbssport, com, collegefootbal, player, player...</td>\n",
       "      <td>cbssport com collegefootbal player playerpag s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538847</th>\n",
       "      <td>aquatixbottle.com/nhftgrg45</td>\n",
       "      <td>bad</td>\n",
       "      <td>[aquatixbottle, com, nhftgrg]</td>\n",
       "      <td>[aquatixbottl, com, nhftgrg]</td>\n",
       "      <td>aquatixbottl com nhftgrg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253662</th>\n",
       "      <td>upcoming.yahoo.com/event/8470024/CA/Oakland-CA...</td>\n",
       "      <td>good</td>\n",
       "      <td>[upcoming, yahoo, com, event, CA, Oakland, CA,...</td>\n",
       "      <td>[upcom, yahoo, com, event, ca, oakland, ca, ch...</td>\n",
       "      <td>upcom yahoo com event ca oakland ca chris tuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421725</th>\n",
       "      <td>remembrance.vt.edu/biographies/couture-nowak.html</td>\n",
       "      <td>good</td>\n",
       "      <td>[remembrance, vt, edu, biographies, couture, n...</td>\n",
       "      <td>[remembr, vt, edu, biographi, coutur, nowak, h...</td>\n",
       "      <td>remembr vt edu biographi coutur nowak html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270830</th>\n",
       "      <td>alacrastore.com/deal-snapshot/JD_Wetherspoon_P...</td>\n",
       "      <td>good</td>\n",
       "      <td>[alacrastore, com, deal, snapshot, JD, Wethers...</td>\n",
       "      <td>[alacrastor, com, deal, snapshot, jd, wethersp...</td>\n",
       "      <td>alacrastor com deal snapshot jd wetherspoon pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102518</th>\n",
       "      <td>richiecranny.com/webb/init/Paype/</td>\n",
       "      <td>bad</td>\n",
       "      <td>[richiecranny, com, webb, init, Paype]</td>\n",
       "      <td>[richiecranni, com, webb, init, payp]</td>\n",
       "      <td>richiecranni com webb init payp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263899</th>\n",
       "      <td>123people.com/c/bill+williams</td>\n",
       "      <td>good</td>\n",
       "      <td>[people, com, c, bill, williams]</td>\n",
       "      <td>[peopl, com, c, bill, william]</td>\n",
       "      <td>peopl com c bill william</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300864</th>\n",
       "      <td>ccnc.ca/content/pr.php?entry=237</td>\n",
       "      <td>good</td>\n",
       "      <td>[ccnc, ca, content, pr, php, entry]</td>\n",
       "      <td>[ccnc, ca, content, pr, php, entri]</td>\n",
       "      <td>ccnc ca content pr php entri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124781</th>\n",
       "      <td>sovetnik4forex.com/libraries/framework/Symfony...</td>\n",
       "      <td>bad</td>\n",
       "      <td>[sovetnik, forex, com, libraries, framework, S...</td>\n",
       "      <td>[sovetnik, forex, com, librari, framework, sym...</td>\n",
       "      <td>sovetnik forex com librari framework symfoni c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398030</th>\n",
       "      <td>mylocalservices.us/listings.php?name=Medical+D...</td>\n",
       "      <td>good</td>\n",
       "      <td>[mylocalservices, us, listings, php, name, Med...</td>\n",
       "      <td>[mylocalservic, us, list, php, name, medic, do...</td>\n",
       "      <td>mylocalservic us list php name medic doctor in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173801</th>\n",
       "      <td>en.wikipedia.org/wiki/David_Emerson</td>\n",
       "      <td>good</td>\n",
       "      <td>[en, wikipedia, org, wiki, David, Emerson]</td>\n",
       "      <td>[en, wikipedia, org, wiki, david, emerson]</td>\n",
       "      <td>en wikipedia org wiki david emerson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291423</th>\n",
       "      <td>billdoll.com/ref/ideas/biz/tt/trans/air/aircra...</td>\n",
       "      <td>good</td>\n",
       "      <td>[billdoll, com, ref, ideas, biz, tt, trans, ai...</td>\n",
       "      <td>[billdol, com, ref, idea, biz, tt, tran, air, ...</td>\n",
       "      <td>billdol com ref idea biz tt tran air aircraft ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404432</th>\n",
       "      <td>nextag.com/30-watt-48-T8-69030897/prices-html</td>\n",
       "      <td>good</td>\n",
       "      <td>[nextag, com, watt, T, prices, html]</td>\n",
       "      <td>[nextag, com, watt, t, price, html]</td>\n",
       "      <td>nextag com watt t price html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70409</th>\n",
       "      <td>news.cnet.com/2100-1040-239394.html</td>\n",
       "      <td>good</td>\n",
       "      <td>[news, cnet, com, html]</td>\n",
       "      <td>[news, cnet, com, html]</td>\n",
       "      <td>news cnet com html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424395</th>\n",
       "      <td>ronmarcus.com/</td>\n",
       "      <td>good</td>\n",
       "      <td>[ronmarcus, com]</td>\n",
       "      <td>[ronmarcus, com]</td>\n",
       "      <td>ronmarcus com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      URL Label  \\\n",
       "164209  delhi.quikr.com/kpmg-india-internship-program-...  good   \n",
       "312733  davidson.k12.nc.us/education/school/school.php...  good   \n",
       "510936                 unmannedsafetyinstitute.org/t76f3g   bad   \n",
       "379285  lonestarball.com/2011/7/7/2263647/series-previ...  good   \n",
       "212195  mediagallery.usatoday.com/2010-11-NHL-season/G...  good   \n",
       "300590  cbssports.com/collegefootball/players/playerpa...  good   \n",
       "538847                        aquatixbottle.com/nhftgrg45   bad   \n",
       "253662  upcoming.yahoo.com/event/8470024/CA/Oakland-CA...  good   \n",
       "421725  remembrance.vt.edu/biographies/couture-nowak.html  good   \n",
       "270830  alacrastore.com/deal-snapshot/JD_Wetherspoon_P...  good   \n",
       "102518                  richiecranny.com/webb/init/Paype/   bad   \n",
       "263899                      123people.com/c/bill+williams  good   \n",
       "300864                   ccnc.ca/content/pr.php?entry=237  good   \n",
       "124781  sovetnik4forex.com/libraries/framework/Symfony...   bad   \n",
       "398030  mylocalservices.us/listings.php?name=Medical+D...  good   \n",
       "173801                en.wikipedia.org/wiki/David_Emerson  good   \n",
       "291423  billdoll.com/ref/ideas/biz/tt/trans/air/aircra...  good   \n",
       "404432      nextag.com/30-watt-48-T8-69030897/prices-html  good   \n",
       "70409                 news.cnet.com/2100-1040-239394.html  good   \n",
       "424395                                     ronmarcus.com/  good   \n",
       "\n",
       "                                           text_tokenized  \\\n",
       "164209  [delhi, quikr, com, kpmg, india, internship, p...   \n",
       "312733  [davidson, k, nc, us, education, school, schoo...   \n",
       "510936            [unmannedsafetyinstitute, org, t, f, g]   \n",
       "379285  [lonestarball, com, series, preview, oakland, ...   \n",
       "212195      [mediagallery, usatoday, com, NHL, season, G]   \n",
       "300590  [cbssports, com, collegefootball, players, pla...   \n",
       "538847                      [aquatixbottle, com, nhftgrg]   \n",
       "253662  [upcoming, yahoo, com, event, CA, Oakland, CA,...   \n",
       "421725  [remembrance, vt, edu, biographies, couture, n...   \n",
       "270830  [alacrastore, com, deal, snapshot, JD, Wethers...   \n",
       "102518             [richiecranny, com, webb, init, Paype]   \n",
       "263899                   [people, com, c, bill, williams]   \n",
       "300864                [ccnc, ca, content, pr, php, entry]   \n",
       "124781  [sovetnik, forex, com, libraries, framework, S...   \n",
       "398030  [mylocalservices, us, listings, php, name, Med...   \n",
       "173801         [en, wikipedia, org, wiki, David, Emerson]   \n",
       "291423  [billdoll, com, ref, ideas, biz, tt, trans, ai...   \n",
       "404432               [nextag, com, watt, T, prices, html]   \n",
       "70409                             [news, cnet, com, html]   \n",
       "424395                                   [ronmarcus, com]   \n",
       "\n",
       "                                             text_stemmed  \\\n",
       "164209  [delhi, quikr, com, kpmg, india, internship, p...   \n",
       "312733  [davidson, k, nc, us, educ, school, school, ph...   \n",
       "510936             [unmannedsafetyinstitut, org, t, f, g]   \n",
       "379285  [lonestarbal, com, seri, preview, oakland, ath...   \n",
       "212195      [mediagalleri, usatoday, com, nhl, season, g]   \n",
       "300590  [cbssport, com, collegefootbal, player, player...   \n",
       "538847                       [aquatixbottl, com, nhftgrg]   \n",
       "253662  [upcom, yahoo, com, event, ca, oakland, ca, ch...   \n",
       "421725  [remembr, vt, edu, biographi, coutur, nowak, h...   \n",
       "270830  [alacrastor, com, deal, snapshot, jd, wethersp...   \n",
       "102518              [richiecranni, com, webb, init, payp]   \n",
       "263899                     [peopl, com, c, bill, william]   \n",
       "300864                [ccnc, ca, content, pr, php, entri]   \n",
       "124781  [sovetnik, forex, com, librari, framework, sym...   \n",
       "398030  [mylocalservic, us, list, php, name, medic, do...   \n",
       "173801         [en, wikipedia, org, wiki, david, emerson]   \n",
       "291423  [billdol, com, ref, idea, biz, tt, tran, air, ...   \n",
       "404432                [nextag, com, watt, t, price, html]   \n",
       "70409                             [news, cnet, com, html]   \n",
       "424395                                   [ronmarcus, com]   \n",
       "\n",
       "                                                text_sent  \n",
       "164209  delhi quikr com kpmg india internship program ...  \n",
       "312733  davidson k nc us educ school school php sectionid  \n",
       "510936                   unmannedsafetyinstitut org t f g  \n",
       "379285  lonestarbal com seri preview oakland athlet te...  \n",
       "212195             mediagalleri usatoday com nhl season g  \n",
       "300590  cbssport com collegefootbal player playerpag s...  \n",
       "538847                           aquatixbottl com nhftgrg  \n",
       "253662  upcom yahoo com event ca oakland ca chris tuck...  \n",
       "421725         remembr vt edu biographi coutur nowak html  \n",
       "270830  alacrastor com deal snapshot jd wetherspoon pl...  \n",
       "102518                    richiecranni com webb init payp  \n",
       "263899                           peopl com c bill william  \n",
       "300864                       ccnc ca content pr php entri  \n",
       "124781  sovetnik forex com librari framework symfoni c...  \n",
       "398030  mylocalservic us list php name medic doctor in...  \n",
       "173801                en wikipedia org wiki david emerson  \n",
       "291423  billdol com ref idea biz tt tran air aircraft ...  \n",
       "404432                       nextag com watt t price html  \n",
       "70409                                  news cnet com html  \n",
       "424395                                      ronmarcus com  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phish_data.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa962e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA CLEANING\n",
    "# noise = [\"[]\"]\n",
    "# df = pd.read_csv('cleaned_data.csv', na_values = noise )\n",
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e387113",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "phish_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404179c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058f1eb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "browser = webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a66d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_urls = ['https://ezee.com/cell-phones/','https://ezee.com/login.php?from=account.php%3Faction%3D'] #here i take phishing sites \n",
    "links_with_text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ccf41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in list_urls:\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "    for line in soup.find_all('a' or 'link'):\n",
    "        href = line.get('href')\n",
    "        links_with_text.append([url, href])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6495414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(links_with_text, columns=[\"from\", \"to\"])\n",
    "# DataFrame is 2D datastructure in pandas.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f27982",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a895b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network graph using networkx \n",
    "GA = nx.from_pandas_edgelist(df, source=\"from\", target=\"to\")\n",
    "nx.draw(GA, with_labels=False) # draws the internal hyperlink redirection network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad34a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer() # converts the tokenized-stemmed words into a sparse matrix in a numerical format w.r.t frequency of word, as machine can't understand words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0529d2ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature = cv.fit_transform(phish_data.text_sent) # converts the tokens into algo-understandable numerical format by calculating different statistical terms like mean, standard deviation etc...,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06875ec7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfeature\u001b[49m[:\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feature' is not defined"
     ]
    }
   ],
   "source": [
    "feature[:5].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0235e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(feature, phish_data.Label)\n",
    "# trainX & testX are compressed sparse matrixes\n",
    "# trainY & testY are splitted datasets \n",
    "# unable to store 1.4TiB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321fe0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter = 549346 ) # Increasing the max_iter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca9967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the lr model with training split data of X & Y \n",
    "lr.fit(trainX,trainY)\n",
    "# ConvergenceWarning: lbfgs failed to converge (status=1): STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "# Increase the number of iterations (max_iter) or scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b411a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# scaler = preprocessing.StandardScaler().fit(trainY) \n",
    "# scaled = scaler.transform(trainX) \n",
    "\n",
    "# cant enter strings to be scaled \n",
    "# sparse matrices can't be chosen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bd6902",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(testX,testY) \n",
    "# accuracy improved from 0.960 --> 0.9664 on increasing the max_iter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b97d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the performance in dictionary \n",
    "score = {}\n",
    "score['LogReg'] = np.round (lr.score(testX,testY) , 3 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf50cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "score['LogReg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9889eec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Training Accuracy :',lr.score(trainX,trainY))\n",
    "print('Testing Accuracy :',lr.score(testX,testY))\n",
    "con_mat = pd.DataFrame(confusion_matrix(lr.predict(testX), testY),\n",
    "            columns = ['Predicted:Bad', 'Predicted:Good'],\n",
    "            index = ['Actual:Bad', 'Actual:Good'])\n",
    "\n",
    "print('\\nCLASSIFICATION REPORT\\n')\n",
    "print(classification_report(lr.predict(testX), testY,\n",
    "                            target_names =['Bad','Good']))\n",
    "\n",
    "print('\\nCONFUSION MATRIX')\n",
    "plt.figure(figsize= (6,4))\n",
    "sb.heatmap(con_mat, annot = True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b66b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# comparing the true labels i.e. true dataset with the predicted dataset and prepares the report of quality of prediction.\n",
    "print(classification_report(testY, lr.predict(testX)))\n",
    "# predictions will be done from sparse matrices. \n",
    "# Accuracy - out of all the good and bad predictions how many of them are acutally true\n",
    "# Precision - out of all good/(+ve) predictions done how many of them are true +ve. similiarly for bad/(-ve)\n",
    "# recall - it simply says how truthful the model is \n",
    "# recall - no. of predicted good / no.of actual real good  \n",
    "# let's say no of +ve s are 6 but predicted are only 4 to be good \n",
    "# recall = 4 / 6 = 0.67\n",
    "# f1 score = harmonic mean of precision & recall\n",
    "# hm = 2*(h1 * h2 ) / ( h1 + h2 ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab38ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MULTINOMIAL NAIVE BAYES ALGORITHM \n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(trainX,trainY) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784ebb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.score(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd74772",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.score(testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d51ddd5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m score[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultiNB\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mround(mnb\u001b[38;5;241m.\u001b[39mscore(testX,testY), \u001b[38;5;241m2\u001b[39m )\n\u001b[0;32m      2\u001b[0m score[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultiNB\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "score['multiNB'] = np.round(mnb.score(testX,testY), 2 )\n",
    "score['multiNB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9565d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Accuracy :',mnb.score(trainX,trainY))\n",
    "print('Testing Accuracy :',mnb.score(testX,testY))\n",
    "con_mat = pd.DataFrame(confusion_matrix(mnb.predict(testX), testY),\n",
    "            columns = ['Predicted:Bad', 'Predicted:Good'],\n",
    "            index = ['Actual:Bad', 'Actual:Good'])\n",
    "\n",
    "print('\\nCLASSIFICATION REPORT\\n')\n",
    "print(classification_report(mnb.predict(testX), testY,\n",
    "                            target_names =['Bad','Good']))\n",
    "\n",
    "print('\\nCONFUSION MATRIX')\n",
    "plt.figure(figsize= (6,4))\n",
    "sb.heatmap(con_mat, annot = True,fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b23b8ac",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4dc145",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter = 549347)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e74ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = make_pipeline(cv(tokenizer.tokenize) , lr ) \n",
    "# arguments - ( preprocessing_techniques , model(i.e. estimator))\n",
    "lr_pipeline = make_pipeline(CountVectorizer(tokenizer = RegexpTokenizer(r'[A-Za-z]+').tokenize,stop_words='english'), lr)\n",
    "# lr_pipeline = make_pipeline(TfidfVectorizer(tokenizer = RegexpTokenizer(r'[A-Za-z]+').tokenize,stop_words='english'), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5695f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# INCLUDING SNOWBALLSTEMMER IN TRANSFORMERS \n",
    "lr_pipeline = make_pipeline(CountVectorizer(tokenizer = RegexpTokenizer(r'[A-Za-z]+').tokenize,SnowballStemmer(),stop_words='english'), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ca7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline = make_pipeline(TfidfTransformer(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df15017",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = cv.fit_transform(phish_data.text_sent) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e40d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model with feature extractions and labelled data \n",
    "trainX, testX, trainY, testY = train_test_split(feature, phish_data.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d7e231",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline.fit(trainX,trainY)\n",
    "lr_pipeline.score(testX,testY) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9ec3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "score['LogReg_tfid_feature_pipeline'] = lr_pipeline.score(testX,testY) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd6fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Accuracy :',lr_pipeline.score(trainX,trainY))\n",
    "print('Testing Accuracy :',lr_pipeline.score(testX,testY))\n",
    "con_mat = pd.DataFrame(confusion_matrix(lr_pipeline.predict(testX), testY),\n",
    "            columns = ['Predicted:Bad', 'Predicted:Good'],\n",
    "            index = ['Actual:Bad', 'Actual:Good'])\n",
    "\n",
    "\n",
    "print('\\nCLASSIFICATION REPORT\\n')\n",
    "print(classification_report(lr_pipeline.predict(testX), testY,\n",
    "                            target_names =['Bad','Good']))\n",
    "\n",
    "print('\\nCONFUSION MATRIX')\n",
    "plt.figure(figsize= (6,4))\n",
    "sb.heatmap(con_mat, annot = True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c95d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lr_pipeline, open('lr_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1244190",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = pickle.load(open('lr_model.pkl','rb'))\n",
    "result = lr_model.score(testX, testY) \n",
    "print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d5411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(result , 2 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48faf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "score['LogReg_pipeline'] = lr_model.score(testX, testY) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c77dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "reg = linear_model.BayesianRidge()\n",
    "reg.fit(trainX,trainY)\n",
    "reg.score(testX,testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dec4dbf",
   "metadata": {},
   "source": [
    "## MULTINOMIAL-NB PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COUNTVECTORIZER TRANSFORMER WITHOUT FEATURES EXTRACTED\n",
    "mnb_pipeline = make_pipeline(CountVectorizer(tokenizer = RegexpTokenizer(r'[A-Za-z]+').tokenize,stop_words = 'english'),mnb)\n",
    "trainX, testX, trainY, testY = train_test_split(phish_data.URL, phish_data.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9450079",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_pipeline.fit(trainX, trainY) \n",
    "mnb_pipeline.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b3c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "score['multiNB_pipeline'] = mnb_pipeline.score(testX, testY) \n",
    "pickle.dump(mnb_pipeline, open('mnb_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8d8c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDFTRANSFORMER WITH FEATURES EXTRACTED\n",
    "mnb_pipeline = make_pipeline(TfidfTransformer(),mnb)\n",
    "trainX, testX, trainY, testY = train_test_split(feature, phish_data.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95fbdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_pipeline.fit(trainX, trainY) \n",
    "mnb_pipeline.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ad833",
   "metadata": {},
   "outputs": [],
   "source": [
    "score['multiNB_tfid_feature_pipeline'] = mnb_pipeline.score(testX, testY) \n",
    "pickle.dump(mnb_pipeline, open('mnb_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f7a65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDFVECTORIZER TRANSFORMER WITH FEATURES EXTRACTED\n",
    "# mnb_pipeline = make_pipeline(TfidfVectorizer(tokenizer = RegexpTokenizer(r'[A-Za-z]+').tokenize,stop_words = 'english'),mnb)\n",
    "# trainX, testX, trainY, testY = train_test_split(feature, phish_data.Label)\n",
    "# VECTORIZERS NEED LOWER BOUND WITH THE FEATURE EXTRACTION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77290cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "mnb_model = pickle.load(open('mnb_model.pkl', 'rb'))\n",
    "# mnb_model.score(testX,testY) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f1751",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Accuracy :',mnb_pipeline.score(trainX,trainY))\n",
    "print('Testing Accuracy :',mnb_pipeline.score(testX,testY))\n",
    "con_mat = pd.DataFrame(confusion_matrix(mnb_pipeline.predict(testX), testY),\n",
    "            columns = ['Predicted:Bad', 'Predicted:Good'],\n",
    "            index = ['Actual:Bad', 'Actual:Good'])\n",
    "\n",
    "print('\\nCLASSIFICATION REPORT\\n')\n",
    "print(classification_report(mnb_pipeline.predict(testX), testY,\n",
    "                            target_names =['Bad','Good']))\n",
    "\n",
    "print('\\nCONFUSION MATRIX')\n",
    "plt.figure(figsize= (6,4))\n",
    "sb.heatmap(con_mat, annot = True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5642ed7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad']\n"
     ]
    }
   ],
   "source": [
    "payload = ['yeniik.com.tr/wp-admin/js/login.alibaba.com/login.jsp.php']\n",
    "print( mnb_model.predict(payload) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61ae1b4",
   "metadata": {},
   "source": [
    "## BERT TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ddde69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\1MYFILES\\ML_NGFW\\FIREWALLS\\-Phishing url detection\n"
     ]
    }
   ],
   "source": [
    "cd D:\\1MYFILES\\ML_NGFW\\FIREWALLS\\-Phishing url detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96061ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    import torch\n",
    "    import transformers as ppb # pytorch transformers\n",
    "    \n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    \n",
    "    import warnings\n",
    "\n",
    "    import swifter\n",
    "    import tqdm\n",
    "    tqdm.pandas()\n",
    "\n",
    "    warnings.filterwarnings('ignore')\n",
    "except Exception  as e: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d5fbcbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = {}\n",
    "df = pd.read_csv('phishing_site_urls.csv')\n",
    "# df = df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96811a04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      2\u001b[0m Y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m      3\u001b[0m encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "X = df[1]\n",
    "Y = df[2]\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b71c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cc6da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTokenizer(object):\n",
    "\n",
    "    def __init__(self, text=[]):\n",
    "        self.text = text\n",
    "\n",
    "        # For DistilBERT:\n",
    "        self.model_class, self.tokenizer_class, self.pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "        # Load pretrained model/tokenizer\n",
    "        self.tokenizer = self.tokenizer_class.from_pretrained(self.pretrained_weights)\n",
    "\n",
    "        self.model = self.model_class.from_pretrained(self.pretrained_weights)\n",
    "\n",
    "    def get(self):\n",
    "\n",
    "        df = pd.DataFrame(data={\"text\":self.text})\n",
    "        tokenized = df[\"text\"].swifter.apply((lambda x: self.tokenizer.encode(x, add_special_tokens=True)))\n",
    "\n",
    "        max_len = 0\n",
    "        for i in tokenized.values:\n",
    "            if len(i) > max_len:\n",
    "                max_len = len(i)\n",
    "\n",
    "        padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "\n",
    "        attention_mask = np.where(padded != 0, 1, 0)\n",
    "        input_ids = torch.tensor(padded)\n",
    "        attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "        with torch.no_grad(): last_hidden_states = self.model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        features = last_hidden_states[0][:, 0, :].numpy()\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8a204d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _instance \u001b[38;5;241m=\u001b[39mBertTokenizer(text\u001b[38;5;241m=\u001b[39m\u001b[43mx_train\u001b[49m)\n\u001b[0;32m      2\u001b[0m tokens \u001b[38;5;241m=\u001b[39m _instance\u001b[38;5;241m.\u001b[39mget()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "_instance =BertTokenizer(text=x_train)\n",
    "tokens = _instance.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04af641a",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2552b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(tokens, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f545de4",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa6e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "_instance =BertTokenizer(text=x_test)\n",
    "tokensTest = _instance.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3201eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = lr_clf.predict(tokensTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489c04aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9742fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35738f86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a41fd51a",
   "metadata": {},
   "source": [
    "# Performance evaluation of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10d4ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.DataFrame.from_dict(score,orient = 'index',columns=['Accuracy'])\n",
    "sb.set_style('darkgrid')\n",
    "sb.barplot(acc.index,acc.Accuracy)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2985d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyngrok nest_asyncio fastapi uvicorn loguru\n",
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "import joblib,os\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from loguru import logger\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "#pkl\n",
    "phish_model = open('lr_model.pkl','rb')\n",
    "phish_model_ls = joblib.load(phish_model)\n",
    "\n",
    "# ML Aspect\n",
    "@app.get('/predict/{feature}')\n",
    "async def predict(features):\n",
    "\tX_predict = []\n",
    "\tX_predict.append(str(features))\n",
    "\ty_Predict = phish_model_ls.predict(X_predict)\n",
    "\tif y_Predict == 'bad':\n",
    "\t\tresult = \"This is a Phishing Site\"\n",
    "\telse:\n",
    "\t\tresult = \"This is not a Phishing Site\"\n",
    "\n",
    "\treturn (features, result)\n",
    "if __name__ == '__main__':\n",
    "\tuvicorn.run(app,host=\"127.0.0.1\",port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36337cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7387bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
